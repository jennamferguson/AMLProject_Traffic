{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31dbfc32-2389-4ce9-aea4-d545d968e154",
   "metadata": {},
   "source": [
    "# Analyzing Traffic Patterns in Austin, Texas\n",
    "Austin, the capital city of Texas, has become a hub for rapid population growth, economic expansion, and increased transportation demands. As the city expands, managing traffic effectively becomes critical in maintaining quality of life, ensuring smooth mobility, and supporting public safety.\n",
    "\n",
    "## Project and Data Overview\n",
    "Our objective is to analyze traffic data collected from several major road intersections in Downtown and Central Austin—**Burnet**, **Congress**, **Lamar**, and **Loop 360**—and leverage machine learning techniques to predict traffic levels. By identifying traffic patterns and trends over time, we aim to provide insights for enhancing urban mobility and reducing congestion in Austin.\n",
    "\n",
    "<img src=\"austinDataMap.jpg\" width=\"450\">\n",
    "\n",
    "### Dataset\n",
    "The dataset, provided by the [City of Austin](https://data.austintexas.gov/Transportation-and-Mobility/Radar-Traffic-Counts/i626-g7ub/about_data), contains traffic volume and speed data collected using Wavetronix radar sensors from June 18, 2017, to September 9, 2021. The data captures volume data per intersection per direction in 15 minute bins, with additional temporal features.\n",
    "\n",
    "The data focuses on a small subset of intersections but provides rich granularity, making it suitable for uncovering actionable patterns. Additionally, it is important to note that this dataset is historical and no longer updated, as the Wavetronix radar sensors were phased out in 2021.\n",
    "\n",
    "### Columns\n",
    "Here is a description of the columns in the dataset:\n",
    "- **`Row ID`**: A unique identifier for each row, created as a hash of `Row ID`, `Detector ID`, and `Intersection Name`.\n",
    "- **`Detector ID`**: A unique number given to each traffic count lane monitored by a radar sensor.\n",
    "- **`KITS ID`**: The ID of the Wavetronix sensor in the city’s Advanced Traffic Management System (KITS).\n",
    "- **`Read Date`**: The timestamp when the radar device collected data.\n",
    "- **`Intersection Name`**: Name of the intersection or general location where the sensor is deployed.\n",
    "- **`Lane`**: Direction and specific lane monitored (e.g., NB-Inside Lane or SB-Outside Lane).\n",
    "- **`Volume`**: Number of vehicles detected in the last 15 minutes.\n",
    "- **`Occupancy`**: The percentage of time a vehicle was detected in the sensor's field of view in the 15-minute period.\n",
    "- **`Speed`**: Average speed of vehicles in the 15-minute period (in mph).\n",
    "- **`Month`**: Numeric representation of the month (e.g., January = 1).\n",
    "- **`Day`**: Numeric representation of the day of the month.\n",
    "- **`Year`**: Year of the data record.\n",
    "- **`Hour`**: Hour of the day when the data was collected (24-hour format).\n",
    "- **`Minute`**: Minute of the hour when the data was collected.\n",
    "- **`Day of Week`**: Day of the week, represented as a number (Sunday = 0, Monday = 1, etc.).\n",
    "- **`Time Bin`**: Text representation of the 15-minute time interval.\n",
    "- **`Direction`**: Traffic direction of the monitored lane (e.g., NB = Northbound, SB = Southbound).\n",
    "\n",
    "*Before we start the analysis, let’s prepare the dataset for exploration.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a08ed09-2c4b-46ff-b097-b5c1110d3d41",
   "metadata": {},
   "source": [
    "## Import Libraries & Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6885530-56c8-4dce-9173-7f9a74591f4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Radar_Traffic_Counts_20241114.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#load data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRadar_Traffic_Counts_20241114.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Radar_Traffic_Counts_20241114.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#load data\n",
    "df = pd.read_csv('Radar_Traffic_Counts_20241114.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02542f72-cbc7-466b-a123-1b786186e677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6834237 entries, 0 to 6834236\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   Row ID             object\n",
      " 1   Detector ID        int64 \n",
      " 2   KITS ID            int64 \n",
      " 3   Read Date          object\n",
      " 4   Intersection Name  object\n",
      " 5   Lane               object\n",
      " 6   Volume             int64 \n",
      " 7   Occupancy          int64 \n",
      " 8   Speed              int64 \n",
      " 9   Month              int64 \n",
      " 10  Day                int64 \n",
      " 11  Year               int64 \n",
      " 12  Hour               int64 \n",
      " 13  Minute             int64 \n",
      " 14  Day of Week        int64 \n",
      " 15  Time Bin           object\n",
      " 16  Direction          object\n",
      "dtypes: int64(11), object(6)\n",
      "memory usage: 886.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506c3e9a-42eb-434e-b82f-f5ac23521655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row ID                    0\n",
       "Detector ID               0\n",
       "KITS ID                   0\n",
       "Read Date                 0\n",
       "Intersection Name         0\n",
       "Lane                      0\n",
       "Volume                    0\n",
       "Occupancy                 0\n",
       "Speed                     0\n",
       "Month                     0\n",
       "Day                       0\n",
       "Year                      0\n",
       "Hour                      0\n",
       "Minute                    0\n",
       "Day of Week               0\n",
       "Time Bin                  0\n",
       "Direction            401274\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of null values for each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a141319-2a5c-429d-a90b-d32822faa898",
   "metadata": {},
   "source": [
    "### Initial Notes:\n",
    "* The dataset contains 6.83M rows and 17 columns.\n",
    "* The `Direction` column contains 401,274 null values, approximately 5.87% of the dataset, posing a problem to data integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c9e803-4d77-4bd6-8e42-ef5039019af3",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "In this section, we process the dataset to prepare it for analysis and modeling. The steps include:\n",
    "- Dropping unrelated columns to reduce complexity.\n",
    "- Handling missing values and filtering data to focus on relevant features.\n",
    "- Grouping traffic data by hour for each intersection and direction, calculating key metrics.\n",
    "- Engineering features such as a `Full Date` column and a `Holiday` indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cb132f-6251-4982-a304-cdf2ab5ace4c",
   "metadata": {},
   "source": [
    "### Dropping Unrelated Columns\n",
    "The dataset includes several columns that are repetitive, unhelpful, or add unnecessary complexity for our project goals. These columns include:\n",
    "- **`Row ID`**, **`Detector ID`, and `KITS ID`**: IDs for each row and traffice monitoring devices, offering no additional insight.\n",
    "- **`Read Date`**: We ran into problems sorting the data referring to this column, as some read dates were clocked out of chronological order due to the date time data type recording exact details (e.g. `2021-09-07 23:00:00` versus `2021-09-07 23:00:01`). The dataset already provides temporal information in separate columns (`Year`, `Month`, `Day`, `Hour`, `Minute`), so we drop this column.\n",
    "- **`Lane`**: Detailed lane information is too granular for this project, though of interest in the future.\n",
    "- **`Occupancy`**: We wanted to include this column, but the data card did not provide a helpful description, plus the range of values did not align with external definitions of this feature.\n",
    "- **`Minute`**: Dropped since analysis focuses on hourly data.\n",
    "- **`Time Bin`**: Textual representation of time, redundant due to numerical time columns.\n",
    "\n",
    "By dropping these columns, we streamline the dataset and focus on meaningful variables for traffic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fbe67f6-eab5-4b51-86f8-d27083b8778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unrelated columns\n",
    "df = df.drop(columns=['Row ID', 'Detector ID', 'KITS ID', 'Read Date', 'Occupancy', 'Lane', 'Minute', 'Time Bin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054703c1-a139-4b03-be2b-ea2ad8b60145",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "To handles issues particularly in the `Direction` column, we:\n",
    "1. Remove rows with any `NaN` values.\n",
    "2. Filter the dataset to include only rows where `Direction` is **NB (Northbound)** or **SB (Southbound)**. \n",
    "   - This decision simplifies the analysis and focuses on primary directions. While Eastbound and Westbound directions are of interest, their inclusion is deferred for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56637f7d-f91d-467d-b498-cfdcd8c2a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nulls\n",
    "df = df.dropna()\n",
    "df = df[df.astype(str).apply(lambda row: 'NaN' not in row.values, axis=1)]\n",
    "\n",
    "#filter out rows whose 'Direction' is not 'NB' or 'SB'\n",
    "df = df[df['Direction'].isin(['NB', 'SB'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e6a276-5a62-4804-a403-7c8e9ee628b7",
   "metadata": {},
   "source": [
    "### Simplifying Intersection Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5050e4b6-1bcc-43cb-b040-7dbc2f027fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intersection Name\n",
       "LOOP 360LAKEWOOD              651342\n",
       "LOOP 360WALSH TARLTON         643972\n",
       "BURNETPALM WAY                515405\n",
       "BurnetRutland                 497380\n",
       "LAMARMANCHACA                 437900\n",
       "LAMARSHOALCREEK               427132\n",
       "LAMARCOLLIER                  390660\n",
       "CONGRESSBARTON SPRINGS        387083\n",
       "LAMARSANDRA MURAIDA           313100\n",
       "CongressJohanna               249248\n",
       "N Lamar15th                   220692\n",
       "LAMARZENNIA                   202620\n",
       "LOOP 360CEDAR                 182920\n",
       "Robert E LeeBarton Springs    111954\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Intersection Name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd80d3d-5915-4e5b-88e6-63968b13f373",
   "metadata": {},
   "source": [
    "The major intersections include Loop 360, Cesar Chavez, Burnet, Lamar, and Congress, with some other (less traveled) roads. Due to limits on computational power, we map the `Intersection Name` column to four major roadways:\n",
    "- **Burnet**, **Congress**, **Lamar**, and **Loop 360**.\n",
    "\n",
    "Rows are mapped based on the presence of these road names in the `Intersection Name` column. Examples:\n",
    "- `BurnetRutland` becomes `BURNET`.\n",
    "- `LOOP 360CEDAR` becomes `LOOP 360`.\n",
    "- `N Lamar 15th` becomes `LAMAR`.\n",
    "\n",
    "Rows that do not match these categories are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddc0de4d-9b6a-4f57-995f-0f8e8c83241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map intersection names\n",
    "df['Road Name'] = df['Intersection Name'].str.upper().apply(\n",
    "    lambda x: 'LOOP 360' if 'LOOP 360' in x else\n",
    "              'LAMAR' if 'LAMAR' in x else\n",
    "              'CONGRESS' if 'CONGRESS' in x else\n",
    "              'BURNET' if 'BURNET' in x else None)\n",
    "\n",
    "#drop rows where 'Road Name' is None & drop original 'Intersection Name' column\n",
    "df = df.dropna(subset=['Road Name']).drop(columns=['Intersection Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1cec9a-6e34-4d34-8ef0-5ebdf519eb29",
   "metadata": {},
   "source": [
    "### Feature Engineering & Sorting\n",
    "We create a new `Full Date` column by combining the `Year`, `Month`, `Day`, and `Hour` columns and setting it to the date time data type. This feature allows us to analyze traffic trends over time as well as sort the data accordingly.\n",
    "\n",
    "Upon closer inspection, we observed:\n",
    "- The date **`2021-09-08`** contains data only up to hour 12 (half a day).\n",
    "- The date **`2021-09-09`** has sparse rows due to the dataset being phased out after September 9, 2021.\n",
    "\n",
    "To maintain data integrity, rows with dates on or after **`2021-09-08`** are removed. The dataset is then sorted by `Full Date` in descending order to ensure the most recent data appears first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f46fa19c-ca9c-4529-9e08-fcc5a033acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 'Full Date' column and drop rows after '2021-09-08'\n",
    "df['Full Date'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour']])\n",
    "df = df[df['Full Date'] < '2021-09-08']\n",
    "\n",
    "#sort dataset\n",
    "df = df.sort_values(by='Full Date', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592cc96b-e834-47a1-85d6-813caefa6eb1",
   "metadata": {},
   "source": [
    "### Grouping and Aggregating Traffic Data\n",
    "For any given day, we wanted to see the average speed and total volume of traffic by the hour, broken down by the available columns. This allows us to analyze hourly traffic trends and identify patterns across different roads and time periods.\n",
    "\n",
    "To achieve this, for each combination of intersection, date, hour, and direction we calculate:\n",
    "1. **Average Speed**: The mean speed of vehicles, rounded to the nearest whole number.\n",
    "2. **Total Volume**: The sum of vehicles detected.\n",
    "\n",
    "To account for missing combinations (e.g., hours with no data), we generate a full cartesian product of all possible combinations of:\n",
    "- `Road Name`\n",
    "- `Year`, `Month`, `Day`\n",
    "- `Hour`\n",
    "- `Direction`\n",
    "\n",
    "Missing values for `Volume` are filled with **0**, while missing `Speed` values remain as `NaN` to avoid introducing bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb455637-6bcb-4887-88b9-7c320055b407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Road Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Full Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BURNET</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>NB</td>\n",
       "      <td>42.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>2021-09-07 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BURNET</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>SB</td>\n",
       "      <td>44.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2021-09-07 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BURNET</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>NB</td>\n",
       "      <td>41.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>2021-09-07 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BURNET</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>SB</td>\n",
       "      <td>43.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>2021-09-07 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BURNET</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>NB</td>\n",
       "      <td>41.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>2021-09-07 21:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Road Name  Month  Day  Year  Hour  Day of Week Direction  Speed  Volume  \\\n",
       "0    BURNET      9    7  2021    23            2        NB   42.0   181.0   \n",
       "1    BURNET      9    7  2021    23            2        SB   44.0   112.0   \n",
       "2    BURNET      9    7  2021    22            2        NB   41.0   259.0   \n",
       "3    BURNET      9    7  2021    22            2        SB   43.0   218.0   \n",
       "4    BURNET      9    7  2021    21            2        NB   41.0   383.0   \n",
       "\n",
       "            Full Date  \n",
       "0 2021-09-07 23:00:00  \n",
       "1 2021-09-07 23:00:00  \n",
       "2 2021-09-07 22:00:00  \n",
       "3 2021-09-07 22:00:00  \n",
       "4 2021-09-07 21:00:00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combos of all possible vals for Road Name, Date, Hour, & Direction\n",
    "unique_dates = df[['Year', 'Month', 'Day', 'Day of Week']].drop_duplicates()\n",
    "unique_road_names = df['Road Name'].unique()\n",
    "unique_hours = pd.DataFrame({'Hour': np.arange(24)})\n",
    "unique_directions = pd.DataFrame({'Direction': ['NB', 'SB']})\n",
    "\n",
    "#generate full cartesian product\n",
    "cartesian = (\n",
    "    unique_dates\n",
    "    .merge(pd.DataFrame({'Road Name': unique_road_names}), how='cross')\n",
    "    .merge(unique_hours, how='cross')\n",
    "    .merge(unique_directions, how='cross'))\n",
    "\n",
    "#calc grouped stats, now including occupancy\n",
    "grouped = (\n",
    "    df.groupby(['Road Name', 'Year', 'Month', 'Day', 'Hour', 'Direction'])\n",
    "    .agg(\n",
    "        Speed=('Speed', lambda x: int(round(x.mean()))),\n",
    "        Volume=('Volume', 'sum')).reset_index())\n",
    "\n",
    "#calc grouped stats\n",
    "grouped = (\n",
    "    df.groupby(['Road Name', 'Year', 'Month', 'Day', 'Hour', 'Direction'])\n",
    "    .agg(\n",
    "        Speed=('Speed', lambda x: int(round(x.mean()))),\n",
    "        Volume=('Volume', 'sum')).reset_index())\n",
    "\n",
    "#merge grouped stats w full cartesian product to fill in missing combos\n",
    "result = cartesian.merge(\n",
    "    grouped,\n",
    "    on=['Road Name', 'Year', 'Month', 'Day', 'Hour', 'Direction'],\n",
    "    how='left')\n",
    "\n",
    "#missing Speed = NaN, missing Volume = 0\n",
    "result['Speed'] = result['Speed']\n",
    "result['Volume'] = result['Volume'].fillna(0)\n",
    "\n",
    "#re-create Full Date col & sort\n",
    "result['Full Date'] = pd.to_datetime(result[['Year', 'Month', 'Day', 'Hour']])\n",
    "result = result.sort_values(by=['Road Name', 'Full Date', 'Hour'], ascending=[True, False, True])\n",
    "\n",
    "#rearrange cols\n",
    "result = result[['Road Name', 'Month', 'Day', 'Year', 'Hour', 'Day of Week', 'Direction', 'Speed', 'Volume', 'Full Date']]\n",
    "\n",
    "#reset index\n",
    "result = result.reset_index(drop=True)\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db4669-15ba-4000-af83-1aed54da0569",
   "metadata": {},
   "source": [
    "### Adding a Holiday Indicator\n",
    "We introduce a `Holiday` column to flag whether a date is a recognized holiday. This feature may help analyze how traffic patterns change on holidays compared to regular days.\n",
    "\n",
    "The holiday dates are pre-defined for each year from 2017 to 2021, covering key national and regional holidays. The holidays used in this analysis are:\n",
    "1. **New Year's Day** (January 1)  \n",
    "2. **Valentine's Day** (February 14)  \n",
    "3. **Easter Sunday** (Varies by year, usually in March or April)  \n",
    "4. **Mother’s Day** (Second Sunday in May)  \n",
    "5. **Memorial Day** (Last Monday in May)  \n",
    "6. **Father’s Day** (Third Sunday in June)  \n",
    "7. **Independence Day** (July 4)  \n",
    "8. **Labor Day** (First Monday in September)  \n",
    "9. **Halloween** (October 31)  \n",
    "10. **Veterans Day** (November 11)  \n",
    "11. **Thanksgiving Day** (Fourth Thursday in November)  \n",
    "12. **Black Friday** (Day after Thanksgiving – unofficial shopping holiday)  \n",
    "13. **Christmas Day** (December 25)  \n",
    "14. **New Year's Eve** (December 31)\n",
    "\n",
    "Each date in the dataset is matched with the corresponding holiday list for its year. The `Holiday` column is then populated as a binary indicator, where:\n",
    "- **1**: Indicates the date is a holiday.\n",
    "- **0**: Indicates the date is not a holiday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca4db7c9-4cc8-4e2a-8c42-b40582c8c1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Road Name</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Full Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BURNET</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NB</td>\n",
       "      <td>42.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>2021-09-07 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BURNET</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>SB</td>\n",
       "      <td>44.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2021-09-07 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BURNET</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NB</td>\n",
       "      <td>41.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>2021-09-07 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BURNET</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>SB</td>\n",
       "      <td>43.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>2021-09-07 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BURNET</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NB</td>\n",
       "      <td>41.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>2021-09-07 21:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Road Name  Month  Day  Year  Hour  Day of Week  Holiday Direction  Speed  \\\n",
       "0    BURNET      9    7  2021    23            2        0        NB   42.0   \n",
       "1    BURNET      9    7  2021    23            2        0        SB   44.0   \n",
       "2    BURNET      9    7  2021    22            2        0        NB   41.0   \n",
       "3    BURNET      9    7  2021    22            2        0        SB   43.0   \n",
       "4    BURNET      9    7  2021    21            2        0        NB   41.0   \n",
       "\n",
       "   Volume           Full Date  \n",
       "0   181.0 2021-09-07 23:00:00  \n",
       "1   112.0 2021-09-07 23:00:00  \n",
       "2   259.0 2021-09-07 22:00:00  \n",
       "3   218.0 2021-09-07 22:00:00  \n",
       "4   383.0 2021-09-07 21:00:00  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define holidays for each year\n",
    "holidays = {\n",
    "    2017: ['01/01', '02/14', '04/16', '05/14', '05/29', '06/18', '04/04', '09/04', '10/31', '11/11', '11/23', '11/24', '12/25', '12/31'],\n",
    "    2018: ['01/01', '02/14', '04/01', '05/13', '05/28', '06/17', '04/04', '09/03', '10/31', '11/11', '11/22', '11/23', '12/25', '12/31'],\n",
    "    2019: ['01/01', '02/14', '04/21', '05/12', '05/27', '06/16', '04/04', '09/02', '10/31', '11/11', '11/28', '11/29', '12/25', '12/31'],\n",
    "    2020: ['01/01', '02/14', '04/12', '05/10', '05/25', '06/21', '04/04', '09/07', '10/31', '11/11', '11/26', '11/27', '12/25', '12/31'],\n",
    "    2021: ['01/01', '02/14', '04/04', '05/09', '05/31', '06/20', '04/04', '09/06', '10/31', '11/11', '11/25', '11/26', '12/25', '12/31']}\n",
    "\n",
    "#func to check if a date is a holiday\n",
    "def is_holiday(row):\n",
    "    year = row['Year']\n",
    "    month_day = row['Full Date'].strftime('%m/%d')\n",
    "    return 1 if year in holidays and month_day in holidays[year] else 0\n",
    "\n",
    "#'Holiday' col\n",
    "result['Holiday'] = result.apply(is_holiday, axis=1)\n",
    "\n",
    "#rearrange columns\n",
    "result = result[['Road Name', 'Month', 'Day', 'Year', 'Hour', 'Day of Week', 'Holiday', 'Direction', 'Speed', 'Volume', 'Full Date']]\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f247b69-17c9-4900-b781-7dd53f7731cc",
   "metadata": {},
   "source": [
    "### Saving the Processed Data\n",
    "After completing all processing steps, the final dataset is saved as a CSV file (`austin_traffic.csv`). This file will serve as the foundation for exploratory data analysis and subsequent modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86963b35-2f1e-49f8-b9e2-c6f24ce53458",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('austin_traffic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf07e432-d63a-4328-b7a8-3d51dd6a0153",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01841605-6f61-4118-b21f-e80a25321cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
